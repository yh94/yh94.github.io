---
title: Spark和Hadoop的异同点分析
date: 2022-06-10
tags:
- java
- 大数据
categories:
- java
- 数据同步
---

### Spark和Hadoop的异同点分析

   [一、两者实现原理的比较](about:blank#_7)
*   [二、 两者多方面的对比](about:blank#__17)
*   [三、Spark和MR两者之间的详细对比分析（重点）](about:blank#SparkMR_39)
*   *   [3.1 速度](about:blank#31__41)
*   [3.2 容错性](about:blank#32__46)
*   [3.3 适用性](about:blank#33__52)
*   [3.4 框架和生态](about:blank#34__58)
*   [3.5 运行环境](about:blank#35__63)
*   [四、三大分布式计算框架系统](about:blank#_74)

（1）`Spark`：是分布式计算平台，是一个用scala语言编写的计算框架，基于内存的快速、通用、可扩展的大数据分析引擎 。

（2）`Hadoop`：是分布式管理、存储、计算的生态系统；  
其中包括三大部分：HDFS（存储）、MapReduce（计算）、Yarn（资源调度）

一、两者实现原理的比较
------------------------------------------------------------------------------

1、Hadoop和Spark都是`并行计算`，两者都是用MR模型进行计算 。Hadoop一个作业称为一个Job，`Job里面分为Map Task和Reduce Task阶段`，每个Task都在自己的进程中运行，当Task结束时，进程也会随之结束。

2、Spark用户提交的任务称为`application`，一个application对应一个SparkContext，app中存在多个job，每触发一次action操作就会产生一个job。这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGScheduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset，由TaskScheduler分发到各个executor中执行；executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取`内存`进行计算。

所以，spark比MR快的原因也在这，MR启动就需要申请资源，用完就销毁，但是spark把进程拿到以后，这个进程会一直存在，即使没有job在跑，所以后边的job可以直接启动，不需要再重新申请资源。

> 注意：一个Application ——> 多个job ——>一个job多个stage ——> 一个stage多个task

二、 两者多方面的对比
------------------------------------------------------------------------------

（1）Spark对标于Hadoop中的计算模块MR，但是速度和效率比MR要快得多；

（2）Spark没有提供文件管理系统，所以，它必须和其他的分布式文件系统进行集成才能运作，它`只是一个计算分析框架`，专门用来对分布式存储的数据进行计算处理，它`本身并不能存储数据`；

（3）Spark可以使用Hadoop的HDFS或者其他云数据平台进行数据存储，但是`一般使用HDFS来进行存储`；

（4）Spark可以使用基于HDFS的HBase数据库，也可以使用HDFS的数据文件，还可以通过jdbc连接使用Mysql数据库数据；`Spark可以对数据库数据进行修改删除`，而HDFS只能对数据进行追加和全表删除；

（5）Spark数据处理速度`秒杀`Hadoop中MR；

（6）Spark处理数据的设计模式与MR不一样，Hadoop是从HDFS读取数据，通过MR将中间结果写入HDFS；然后再重新从HDFS读取数据进行MR，再刷写到HDFS，这个过程涉及多次落盘操作，多次磁盘IO，效率并不高；而Spark的设计模式是读取集群中的数据后，在`内存`中存储和运算，直到全部运算完毕后，再存储到集群中；

（7）Spark是由于Hadoop中MR效率低下而产生的高效率快速计算引擎，批处理速度比MR快近10倍，内存中的数据分析速度比Hadoop快近100倍（源自官网描述）；

（8）Spark中RDD一般存放在内存中，如果内存不够存放数据，会同时使用磁盘存储数据；通过RDD之间的血缘连接、数据存入内存中切断血缘关系等机制，可以实现灾难恢复，当数据丢失时可以恢复数据；这一点与Hadoop类似，Hadoop基于磁盘读写，天生数据具备可恢复性；

（9）Spark引进了内存集群计算的概念，可`在内存集群计算中将数据集缓存在内存中`，以缩短访问延迟；

（10）Spark中通过DAG有向无环图可以实现良好的容错。

三、Spark和MR两者之间的详细对比分析（重点）
--------------------------------------------------------------------------------------------

### 3.1 速度

（1）spark把运算的中间数据存放在`内存`，迭代计算效率更高；

（2）mapreduce的中间结果需要保存到`磁盘`， 这样必然会有磁盘io操做，影响性能。

### 3.2 容错性

（1）spark容错性高，它通过`弹性分布式数据集RDD`来实现高效容错，RDD是一组分布式的存储在节点内存中的`只读`性质的数据集，这些集合是弹性的，某一部分丢失或者出错，可以通过整个数据集的计算流程的血缘关系来实现重建；

（2）mapreduce的容错可能只能重新计算了，成本较高。

### 3.3 适用性

（1）spark更加通用，spark提供了transformation和action这两大类的多个功能API，另外还有流式处理 sparkstreaming模块、图计算GraphX等等；

（2）mapreduce只提供了map和reduce两种操作，流计算以及其他模块的支持比较缺乏。

### 3.4 框架和生态

（1）Spark框架和生态更为复杂适用范围更广，首先由RDD、血缘lineage、执行时的有向无环图DAG、stage划分等等，很多时候spark作业都需要根据不同的业务场景的需要进行调优，以达到性能要求。

（2）MR框架及其生态相对较为简单，对性能的要求也相对较弱，但是运行较为稳定，`适合长期后台运行以及离线海量数据挖掘计算`。

### 3.5 运行环境

（1）spark大致有四种运行模式：

> `local`：本地运行  
> `standalone`：使用Spark自带的资源管理框架，运行spark的应用（**常用**）  
> `yarn`：将spark应用类似mr一样，提交到yarn上运行 （**常用**）  
> `mesos`：类似yarn的一种资源管理框架

（2）MR运行在YARN上

四、三大分布式计算框架系统
--------------------------------------------------------------------------------

（1）`Mapreduce`适合处理海量离线的静态数据；

（2）`Spark`对实时的数据做批处理；

（3）`Storm/Flink`对实时在线的数据做流式处理。



